# -*- coding: utf-8 -*-
"""Práctica_Ciencia_Datos_SIEII.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d_D5GXIgfcJ90F1Klw2EWfURbq6cOaYZ

# Ciencia de Datos
*Práctica 3 de Sistemas de la Información II*

Por Carlos Moragón y Paloma Pérez de Madrid

---

### Introducción

Esta práctica tiene como objetivo principal la aplicación de técnicas de aprendizaje automático para predecir si la calidad de un plátano es **buena** o **mala** en función de atributos como la acidez, la dulzura, tamaño, peso, ...

El conjunto de datos lo hemos obtenido de Kaggle: https://www.kaggle.com/datasets/l3llff/banana?resource=download
*Nota*: Para comenzar la práctica, debe descargarse dicho conjunto de datos y subirlos al notebook (icono de la carpeta en el menú del lazo izquierdo)

### Objetivos

1. Explorar y comprender el conjunto de datos proporcionado.
2. Preprocesar los datos para su posterior modelado.
3. Implementar el algoritmo de XGBoost para la predicción de la calidad del plátano
4. Evaluar el rendimiento del modelo de XGBoost utilizando métricas de evaluación pertinentes.

### Pasos a Seguir

1. **Exploración de Datos**: Se realizó un análisis exploratorio de los datos para comprender la distribución, la relación entre las variables y la presencia de valores atípicos.

2. **Preprocesamiento de Datos**: Escalado de características para normalizar su distribución, codificación de la variable categórica Quality mediante técnicas como one-hot encoding, eliminación de observaciones con valores NaN para garantizar la integridad del conjunto de datos, la identificación y eliminación de valores atípicos utilizando métodos basados en quantiles, la ingeniería de características para capturar información relevante, la eliminación de características con baja variabilidad o correlación y el balanceo de clases mediante técnicas como submuestreo o sobremuestreo para abordar el desequilibrio de clases.

3. **Implementación de XGBoost**: Se implementó el algoritmo de XGBoost utilizando la biblioteca correspondiente en h2o. Además se implementaron otros modelos para demostrar el rendimiento superior de XGBoost respecto al resto

4. **Evaluación del Modelo**: Se evaluó el rendimiento del modelo de XGBoost utilizando métricas de evaluación como Matriz de Consfusión,Curva ROC,Umbral,LIFT, SCORER y otras evaluaciones comunes como Precisión, RecallF1-Score, Exactitud (Accuracy), Especificidad, AUC-PR (Área bajo la curva Precision-Recall).

### Conclusiones

La práctica proporciona una visión completa del proceso de construcción y evaluación de modelos predictivos utilizando exclusivamente XGBoost en el contexto de etiquetar si un plátano tiene es bueno o malo.
"""

!pip install h2o

import h2o
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from imblearn.over_sampling import SMOTE

"""Descargamos los datos de nuestro kaggle."""

df = pd.read_csv('data/banana_quality.csv')
# https://www.kaggle.com/datasets/l3llff/banana?resource=download

df

"""¿Qué significan estos datos?
* Size - Tamaño de la fruta
* Weight - Peso de la fruta
* Sweetness - Dulzura de la fruta
* Softness - Suavidad de la fruta
* HarvestTime - Cantidad de tiempo transcurrido desde la cosecha de la fruta
* Ripeness - Madurez de la fruta
* Acidity - Acidez de la fruta
* Quality - Calidad de la fruta

¿Podríamos añadir alguna variable más?

## Análisis de datos.

Plots:
* Histograma de la distribución de Calidad
* Matriz de Correlación
* Histograma distribución de la dulzura
* Box Plot de la Acidez por Calidad
"""

plt.hist(df['Quality'], bins=20, color='skyblue', edgecolor='black')
plt.xlabel('Quality')
plt.ylabel('Frequency')
plt.title('Histogram: Quality Distribution')
plt.show()

"""Dado el gráfico, podemos suponer que la distribución de plátanos de buena y mala calidad es equiparable, luego no hay sesgo.

La matriz de correlación es una medida que varía en el rango de -1 a 1.

Un valor de 1 indica una correlación perfecta positiva, lo que significa que cuando una variable aumenta, la otra variable también aumenta en proporción constante.
Un valor de -1 indica una correlación perfecta negativa, lo que significa que cuando una variable aumenta, la otra variable disminuye en proporción constante.
Un valor de 0 indica que no hay correlación entre las variables.
"""

# Eliminar la columna 'Quality' del DataFrame antes de calcular la matriz de correlación
numeric_df = df.drop(columns=['Quality'])

# Calcular la matriz de correlación
correlation_matrix = numeric_df.corr()

# Visualizar la matriz de correlación como un mapa de calor
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriz de Correlación')
plt.show()

"""Conclusiones del gráfico:
* El tiempo de cosecha está altamente relacionado con el tamaño
* Hay una tendencia moderada de que los plátanos más ácidos tiendan a tener un peso ligeramente mayor y al revés
* Hay una tendencia moderada de que los plátanos más ácidos tiendan a tener una dulzura ligeramente mayor y al revés
"""

plt.hist(df['Sweetness'], bins=20, color='skyblue', edgecolor='black')
plt.xlabel('Sweetness')
plt.ylabel('Frequency')
plt.title('Histogram: Sweetness Distribution')
plt.show()

"""La mayoría de las personas consideran que un plátano es bueno cuanto más dulce es.

Para ello visualizaremos que cantidad de plátanos dulces se consideran buenos
"""

# Primero averiguaremos el valor máximo y el valor mínimo de la columna de la dulzura
umbral_alta_dulzura = df['Sweetness'].quantile(0.75)
valor_maximo = df['Sweetness'].max()
valor_minimo = df['Sweetness'].min()

print(f'Umbral de alta dulzura, cuantil 75% : {umbral_alta_dulzura}')
print("Valor máximo de dulzura:", valor_maximo)
print("Valor mínimo de dulzura:", valor_minimo)

"""Por tanto consideraremos que
* 7.539374 = puntuación de 10
* -6.4340215 = puntuación de 0

El 75% de los datos está por debajo de 0.311047995

Diremos que un plátano es altamente dulce si tiene una puntuación de mayor a 0.311047995
"""

# Rango de alta dulzura

# Conteo de plátanos con alta dulzura por calidad
alta_dulzura_buena_calidad = df[(df['Quality'] == 'Good') & (df['Sweetness'] >= umbral_alta_dulzura)].shape[0]
alta_dulzura_mala_calidad = df[(df['Quality'] == 'Bad') & (df['Sweetness'] >= umbral_alta_dulzura)].shape[0]

# Gráfico de barras
plt.figure(figsize=(8, 6))
sns.countplot(x='Quality', hue=pd.cut(df['Sweetness'], bins=[df['Sweetness'].min(), umbral_alta_dulzura, df['Sweetness'].max()], labels=['No Alta Dulzura', 'Alta Dulzura']), data=df)
plt.title('Distribución de alta dulzura por calidad de plátanos')
plt.xlabel('Calidad')
plt.ylabel('Cantidad de plátanos')
plt.legend(title='Dulzura')
plt.show()


print(f'Plátanos con alta dulzura y buena calidad: {alta_dulzura_buena_calidad}')
print(f'Plátanos con alta dulzura y mala calidad: {alta_dulzura_mala_calidad}')

# Conteo total de plátanos por calidad
total_buena_calidad = df[df['Quality'] == 'Good'].shape[0]
total_mala_calidad = df[df['Quality'] == 'Bad'].shape[0]

# Porcentaje de plátanos con alta dulzura respecto al total por calidad
porcentaje_alta_dulzura_buena_calidad = (alta_dulzura_buena_calidad / total_buena_calidad) * 100
porcentaje_alta_dulzura_mala_calidad = (alta_dulzura_mala_calidad / total_mala_calidad) * 100

print(f'Porcentaje de plátanos con alta dulzura y buena calidad: {porcentaje_alta_dulzura_buena_calidad:.2f}%')
print(f'Porcentaje de plátanos con alta dulzura y mala calidad: {porcentaje_alta_dulzura_mala_calidad:.2f}%')

"""Como se observa, menos de la mitad de plátanos con alta dulzura son de buena calidad. Por tanto, descartamos la hipótesis de que si un plátano es dulce, su calidad será favorable

**Calcular el efecto de cada variable predictora** en la probabilidad de que un plátano sea de buena calidad
"""

import statsmodels.api as sm

# Variables predictoras (X) y variable objetivo (y)
X = df.drop(columns=['Quality'])  # Todas las columnas excepto 'Quality'
y = (df['Quality'] == 'Good').astype(int)  # Convertir 'Good' a 1 y 'Bad' a 0 para análisis de regresión logística

X = sm.add_constant(X)  # constante a las variables predictoras para el término de intercepción

modelo = sm.Logit(y, X).fit() # Ajustar modelo de regresión logística

print(modelo.summary())

"""- **Coeficientes:**
  - **Tamaño (Size):** Por cada unidad de aumento en el tamaño del plátano, la probabilidad de que sea de buena calidad aumenta en aproximadamente un 66.94%, manteniendo todas las demás variables constantes.
  - **Peso (Weight):** Por cada unidad de aumento en el peso del plátano, la probabilidad de que sea de buena calidad aumenta en aproximadamente un 98.41%, manteniendo todas las demás variables constantes.
  - **Dulzura (Sweetness):** Por cada unidad de aumento en la dulzura del plátano, la probabilidad de que sea de buena calidad aumenta en aproximadamente un 78.74%, manteniendo todas las demás variables constantes.
  - **Suavidad (Softness):** Por cada unidad de aumento en la suavidad del plátano, la probabilidad de que sea de buena calidad aumenta en aproximadamente un 8.02%, manteniendo todas las demás variables constantes.
  - **Tiempo de Cosecha (HarvestTime):** Por cada unidad de aumento en el tiempo de cosecha del plátano, la probabilidad de que sea de buena calidad aumenta en aproximadamente un 57.58%, manteniendo todas las demás variables constantes.
  - **Madurez (Ripeness):** Por cada unidad de aumento en la madurez del plátano, la probabilidad de que sea de buena calidad aumenta en aproximadamente un 59.93%, manteniendo todas las demás variables constantes.
  - **Acidez (Acidity):** Por cada unidad de aumento en la acidez del plátano, la probabilidad de que sea de buena calidad disminuye en aproximadamente un 11.15%, manteniendo todas las demás variables constantes.

- **Significancia estadística (p-valores):**
  - Todos los coeficientes tienen p-valores prácticamente cero, lo que indica una alta significancia estadística de las variables predictoras.

- **Intervalos de confianza (95%):**
  - Para cada coeficiente, se proporcionan los intervalos de confianza del 95%, que representan el rango de valores plausibles para el coeficiente en la población.
- **Dirección del efecto**: Las direcciones de los coeficientes (positivos o negativos) nos indican cómo cada variable influye en la calidad del plátano. Por ejemplo, un tamaño, peso, dulzura, suavidad, tiempo de cosecha y madurez mayores están asociados con una mayor probabilidad de que el plátano sea de buena calidad, mientras que un nivel más alto de acidez está asociado con una menor probabilidad de buena calidad.

El modelo de regresión logística muestra que las variables predictoras (tamaño, peso, dulzura, suavidad, tiempo de cosecha, madurez y acidez) son significativas para predecir la calidad del plátano, con coeficientes positivos para la mayoría de las variables, lo que indica una asociación positiva con la calidad del plátano.

_________________________________________________________
Dada la importancia del Peso, vamos a visualizar el impacto del peso como hemos hecho con la dulzura
"""

umbral_alto_peso = df['Weight'].quantile(0.75)
valor_maximo = df['Weight'].max()
valor_minimo = df['Weight'].min()

print(f'Umbral de alto peso, cuantil 75% : {umbral_alto_peso}')
print("Valor máximo del peso:", valor_maximo)
print("Valor mínimo del peso:", valor_minimo)

# Rango de alta dulzura

# Conteo de plátanos con alto peso por calidad
alto_peso_buena_calidad = df[(df['Quality'] == 'Good') & (df['Weight'] >= umbral_alto_peso)].shape[0]
alto_peso_mala_calidad = df[(df['Quality'] == 'Bad') & (df['Weight'] >= umbral_alto_peso)].shape[0]

# Gráfico de barras
plt.figure(figsize=(8, 6))
sns.countplot(x='Quality', hue=pd.cut(df['Weight'], bins=[df['Weight'].min(), umbral_alto_peso, df['Weight'].max()], labels=['Bajo Peso', 'Alto Peso']), data=df)
plt.title('Distribución de alto peso por calidad de plátanos')
plt.xlabel('Calidad')
plt.ylabel('Cantidad de plátanos')
plt.legend(title='Peso')
plt.show()


print(f'Plátanos con alto peso y buena calidad: {alto_peso_buena_calidad}')
print(f'Plátanos con alto peso y mala calidad: {alto_peso_mala_calidad}')

# Porcentaje de plátanos con alto peso respecto al total por calidad
porcentaje_alto_peso_buena_calidad = (alto_peso_buena_calidad / total_buena_calidad) * 100
porcentaje_alto_peso_mala_calidad = (alto_peso_mala_calidad / total_mala_calidad) * 100

print(f'Porcentaje de plátanos con alta dulzura y buena calidad: {porcentaje_alta_dulzura_buena_calidad:.2f}%')
print(f'Porcentaje de plátanos con alta dulzura y mala calidad: {porcentaje_alta_dulzura_mala_calidad:.2f}%')

"""**Nuevas variables**

Después de una evaluación exhaustiva de los datos y las variables disponibles, así como de las posibles variables adicionales, determinamos que no existe información adicional relevante que pueda ser capturada por nuevas variables y que mejore significativamente la capacidad predictiva del modelo, entonces es justificable no añadir nuevas variables. Hemos mantenido el modelo simple para evitar el riesgo de sobreajuste y mantener la interpretabilidad del modelo.

## Transformaciones / Tratamiento de datos.

* Escalamos las características.
* Analizamos los valores NA.
* Analizamos los valores atípicos.
* Analizamos la creación nuevas variables.
* Analizamos la elimincación de características irrelevantes.
* Analizamos la necesidad de balanceo de clases.

Al **escalar las características**, las estamos transformando de manera que tengan una media cercana a cero y una desviación estándar de uno (en el caso del `StandardScaler`). Esto ayuda a evitar que una variable con un rango de valores mucho más grande domine sobre las demás variables durante el ajuste del modelo.
"""

# Hacer esto con los datos de train
scaler = StandardScaler()
# df_mid = df.drop('Quality', axis=1).scale().as_data_frame()
scaler.fit(df.drop('Quality', axis=1))
scaled_features = scaler.transform(df.drop('Quality', axis=1))
df_transformado = pd.DataFrame(scaled_features, columns=df.columns[:-1])

"""Codificamos la variable Quality a (1 y 0)
* Algoritmos de aprendizaje automático, como la regresión logística o las máquinas de vectores de soporte (SVM), es necesario codificar las variables categóricas en forma numérica,
* Algoritmos como los árboles de decisión y sus variantes como Random Forest y XGBoost, no es necesario codificar la variable de calidad en forma numérica (ya que puede manejar variables categóricas directamente sin necesidad de codificación)

Como vamos a comparar varios modelos (XGBoost, RandomForest y Regresion) procedemos a codificar las variables



"""

# linea puede que no haga falta
# df_transformado = df

# A partir de aquí si hace falta 100%
label_encoder = LabelEncoder()
df_transformado['Quality_encoded'] = label_encoder.fit_transform(df['Quality'])

"""Analizamos los valores NA
* Si existen, en este caso tiene sentido borrar el registro, ya que queremos analizar en base a todas las características mencionadas anteriormente cuál es la calidad del plátano
* Si no existen, se deja el df como tal

"""

df_transformado.drop('Quality', axis=1)
df_transformado.isna().sum()

"""Analizamos los **valores atípicos**:
* Visualizaremos los boxplot para cada característica numérica, si vemos algún dato fuera del boxplot
"""

sns.set(style="whitegrid")
plt.figure(figsize=(12, 6))
df_boxplot = df_transformado.copy()
df_boxplot = df_boxplot.drop(columns=('Quality_encoded'))
sns.boxplot(data=df_boxplot)
plt.title("Boxplot de características numéricas")
plt.xticks(rotation=45)
plt.show()

"""Vemos que hay bastantes valores atípicos, procedemos a tratarlos

Un método común para eliminar los valores atípicos es utilizar el rango intercuartílico (IQR). El IQR es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1) de una distribución de datos. Los valores atípicos se definen generalmente como aquellos que están por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR.

no borrar los datos, asignarlo a un máximo o un mínimo o utilizas un algortimo LOF y ver cuanto te da. LOF: si un registro en si es anormal
"""

# Calcular el rango intercuartílico (IQR)
df_numerico = df_transformado.drop(columns=['Quality'])
df_numerico = df_numerico.select_dtypes(include=['number'])
q1 = df_numerico.quantile(0.25)
q3 = df_numerico.quantile(0.75)
iqr = q3 - q1

# Definir los límites inferior y superior para identificar valores atípicos
lower_limit = q1 - 1.5 * iqr
upper_limit = q3 + 1.5 * iqr

# Eliminar los valores atípicos
df_transformado = df_numerico[~((df_numerico < lower_limit) | (df_numerico > upper_limit)).any(axis=1)]
df_transformado

"""Conclusiones de los valores atípicos:

1. Hay una cantidad considerable de valores atípicos en las columnas numéricas del conjunto de datos, lo que puede afectar negativamente el rendimiento de algunos modelos de aprendizaje automático.

2. Se ha elegido utilizar el método del rango intercuartílico (IQR) para identificar y eliminar estos valores atípicos. Este método es comúnmente utilizado y ayuda a eliminar valores extremos que pueden distorsionar los resultados de análisis y modelos predictivos.

3. Después de aplicar el método del IQR, se ha creado un nuevo DataFrame `df_transformado` que contiene únicamente las filas que no contienen valores atípicos en ninguna de las columnas numéricas.

4. Este proceso de eliminación de valores atípicos puede mejorar la calidad de los datos y permitir un análisis más robusto y confiable.

**Eliminamos características irrelevantes**

Lo haremos en base a los coeficientes obtenidos del análisis de el efecto de cada variable predictora , consideraremos eliminar aquellas características que tienen un impacto menor en la probabilidad de que el plátano sea de buena calidad

En base a los coeficientes proporcionados:

- La suavidad (Softness) parece tener el menor impacto en la probabilidad de buena calidad, con un coeficiente de aproximadamente 0.0802, lo que indica un aumento del 8.02% en la probabilidad de buena calidad por cada unidad de aumento en la suavidad. Aunque todavía contribuye al modelo, su impacto es el más bajo de todas las características.

- Otro enfoque sería establecer un umbral arbitrario para la importancia de las características y eliminar aquellas que caen por debajo de ese umbral. Por ejemplo, podríamos decidir eliminar características con coeficientes inferiores a 0.05 o 0.1 si consideramos que su impacto es demasiado bajo en comparación con otras características.

En este caso nos decantaremos por el umbral arbitrario. Consideramos que no es óptimo eliminar datos ya que el dataset es en sí de un tamaño reducido. Además, el coeficiente de la siavidad es del 8.02%, lo que nos indica que contribuye al modelo lo suficiente.

_______________________________________________________
"""

umbral_coeficiente = 0.05  # Puedes ajustar este umbral según tus necesidades

caracteristicas_a_eliminar = []

for caracteristica, coeficiente in modelo.params.items():
    if abs(coeficiente) < umbral_coeficiente:
        caracteristicas_a_eliminar.append(caracteristica)

df_sin_caracteristicas_irrelevantes = df.drop(columns=caracteristicas_a_eliminar)

print("Características eliminadas:", caracteristicas_a_eliminar)
print(df_sin_caracteristicas_irrelevantes.head())

"""Conclusión: No se eliminaron características.

Explicación: Ninguna característica tuvo un coeficiente por debajo del umbral establecido, lo que sugiere que todas las características tienen un impacto significativo en la calidad del plátano según el modelo de regresión logística.

____________________________________________________

El balanceo de clases no es necesario al tener igual de casos en 'Good' que en 'Bad', pero lo ponemos para saber como hacerlo :)
"""

X = df_sin_caracteristicas_irrelevantes.drop(columns=['Quality', 'Quality_encoded'])
y = df_sin_caracteristicas_irrelevantes['Quality_encoded']

# Aplicar SMOTE para balancear las clases
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Mostrar las dimensiones de los datos después de aplicar SMOTE
print("Dimensiones de X después de SMOTE:", X_resampled.shape)
print("Dimensiones de y después de SMOTE:", y_resampled.shape)

"""## Modelo"""

# TIENES QUE COMPARAR VARIOS MODELOS Y SUS

from h2o.estimators import H2OXGBoostEstimator
from h2o.grid.grid_search import H2OGridSearch
from h2o.estimators import H2ODeepLearningEstimator
from h2o.estimators.random_forest import H2ORandomForestEstimator

"""Crearemos 3 modelos para comparar sus competencias al hacer comparaciones:
* Deep Learning (Neural Networks)
* Distributed Random Forest (DRF)
* XGBoost
"""

h2o.init()

data = h2o.H2OFrame(df_transformado) # sobre df??

"""<h1>Creación de subconjuntos de datos</h1>"""

# Size	Weight	Sweetness	Softness	HarvestTime	Ripeness	Acidity	Quality_encoded	Size_HarvestTime
predictors = ["Size", "Weight", "Sweetness", "Softness", "HarvestTime", "Ripeness", "Acidity"]#, "Size_HarvestTime"] #<- Ya no está Size_harvesttime
response = "Quality_encoded"

data[response] = data[response].asfactor() # Calidad --> Categoría

# Dividir los datos en train + dev + test
train, test, dev = data.split_frame(ratios=[0.75, 0.15], destination_frames = ['train_df', 'test_df', 'val_df'],
                                    seed=566)

# train = train.drop('Quality', axis=1)

train

'''
scaler = StandardScaler()
df_train = train.drop('Quality', axis=1).scale().as_data_frame() # No nos hace falta Quality, para eso tenemos Quality_encoded
print(df_train)
scaler.fit(df_train)
scaled_features = scaler.transform(df_train)
# con los datos de train --> transform de scaler [BORRAR MORAGÓN]
df_transformado = pd.DataFrame(scaled_features, columns=df.columns[:-1])
'''

"""<h1>Deep Learning (Neural Networks)</h1>"""

#df_train = h2o.H2OFrame(df_transformado)

#dev['Quality_encoded'] = dev['Quality_encoded'].asfactor() #Se está tratando Quality_encoded como numeros en vez de categorias

# Deep Learning (Neural Networks)
rrnn = H2ODeepLearningEstimator()

rrnn.train(x=predictors, y=response, training_frame=train, validation_frame=dev)

# Verificar el rendimiento del modelo en los datos de prueba
rendimiento_antes_rrnn= rrnn.model_performance(test_data=test)
print(rendimiento_antes_rrnn)

## Modelo Final ##

print(f'mi modelo es {rrnn}')
print("\n \n ****************************************************\n \n")
print(f'su rendimiento: {rendimiento_antes_rrnn}')

"""<h1>Distributed Random Forest (DRF)</h1>"""

drf = H2ORandomForestEstimator()

drf.train(x=predictors, y=response, training_frame=train, validation_frame=dev)

# Verificar el rendimiento del modelo en los datos de prueba
rendimiento_antes_drf= drf.model_performance(test_data=test)
print(rendimiento_antes_drf)

"""<h1>XGBOOST</h1>"""

# Crear un modelo XGBoost
xgb = H2OXGBoostEstimator()
xgb.train(x=predictors, y=response, training_frame=train, validation_frame=dev)

"""**Búsqueda de Hiperparámetros**:

Es un proceso para encontrar la mejor configuración de ajustes *previos* (hiperparámetros) para un modelo de aprendizaje automático. Implica probar diferentes combinaciones de valores de hiperparámetros y evaluar el rendimiento del modelo para cada combinación.

**Objetivo**: es optimizar métricas de evaluación como precisión, área bajo la curva ROC o pérdida logarítmica.

**Cómo**:
1. Definir los hiperparámetros a probar (número de árboles, profundidad, tasa de aprendizaje, ...)
2. Crear el *grid* de búsqueda:  técnica utilizada para explorar de manera sistemática un espacio de hiperparámetros con el objetivo de encontrar la mejor combinación de valores para un modelo de aprendizaje automático
3. Entrenar el *grid*
4. Elegir el mejor modelo del *grid* de búsqueda
"""

# Verificar el rendimiento del modelo en los datos de prueba
rendimiento_antes_xgb= xgb.model_performance(test_data=test)
print(rendimiento_antes_xgb)

# Ahora entrenaremos otro modelo para ver la influencia de los hiperparámetros

## Búsqueda de Hiperparámetros ##

# Definir los hiperparámetros a probar
hyper_parameters = {'ntrees': [50, 100, 150, 200, 300], 'max_depth': [3, 5, 7, 8, 9], 'learn_rate': [0.1, 0.01, 0.001, 0.0001, 0.00001]}

# Crear el grid de búsqueda
grid_search = H2OGridSearch(H2OXGBoostEstimator(), hyper_parameters)

# Entrenar el grid de búsqueda
grid_search.train(x=predictors, y=response, training_frame=train, validation_frame=dev)

# Obtener el mejor modelo del grid de búsqueda
best_model = grid_search.get_grid()[0]

## Verificar el rendimiento del mejor modelo ##
rendimiento_despues = best_model.model_performance(test_data=test)
print(rendimiento_despues)

# Vamos a comparar rápidamente el rendimiento antes y después

## Precisión ##
precision_antes = rendimiento_antes.precision()
print("Precisión antes de la búsqueda de hiperparámetros:", precision_antes)

precision_despues = rendimiento_despues.precision()
print("Precisión después de la búsqueda de hiperparámetros:", precision_despues)

# Comparar el rendimiento antes y después de la búsqueda de hiperparámetros
if precision_despues > precision_antes:
    print("El rendimiento mejoró después de la búsqueda de hiperparámetros.")
elif precision_despues < precision_antes:
    print("El rendimiento empeoró después de la búsqueda de hiperparámetros.")
else:
    print("El rendimiento se mantuvo igual antes y después de la búsqueda de hiperparámetros.")

## Curva ROC ##
auc_antes = rendimiento_antes.auc()
print("AUC antes de la búsqueda de hiperparámetros:", auc_antes)

auc_despues = rendimiento_despues.auc()
print("AUC después de la búsqueda de hiperparámetros:", auc_despues)

# Comparar el rendimiento antes y después de la búsqueda de hiperparámetros
if auc_despues > auc_antes:
    print("El rendimiento mejoró después de la búsqueda de hiperparámetros.")
elif auc_despues < auc_antes:
    print("El rendimiento empeoró después de la búsqueda de hiperparámetros.")
else:
    print("El rendimiento se mantuvo igual antes y después de la búsqueda de hiperparámetros.")

"""Como se puede observar, el uso de hiperparámetros no mejora el modelo, luego no los usaremos"""

## Modelo Final ##

print(f'mi modelo es {xgb}')
print("\n \n ****************************************************\n \n")
print(f'su rendimiento: {rendimiento_antes_xgb}')

"""## Evaluación
- Matriz de Consfusión
- Curva ROC
- Umbral
- LIFT
- SCORER

Otras evaluaciones comunes:

1. Precisión: La proporción de verdaderos positivos (TP) sobre el total de predicciones positivas (TP + FP).
2. Recall (Sensibilidad): La proporción de verdaderos positivos (TP) sobre el total de positivos reales (TP + FN).
3. F1-Score: La media armónica de precisión y recall. Es útil cuando hay un desequilibrio entre las clases.
4. Exactitud (Accuracy): La proporción de predicciones correctas (TP + TN) sobre el total de predicciones.
5. Especificidad: La proporción de verdaderos negativos (TN) sobre el total de negativos reales (TN + FP).
6. AUC-PR (Área bajo la curva Precision-Recall): La integral de la curva Precision-Recall. Es útil cuando hay desequilibrio de clases y te interesa más el rendimiento en la clase minoritaria.

Matriz de confusión:
"""

rendimiento_antes_xgb.confusion_matrix()

rendimiento_antes_rrnn.confusion_matrix()

rendimiento_antes_drf.confusion_matrix()

"""Curva ROC:"""

roc_curve=rendimiento_antes_xgb.roc()


# Extraer los valores de tasa de verdaderos positivos (TPR) y tasa de falsos positivos (FPR)
fpr = roc_curve[0]
tpr = roc_curve[1]

# Graficar la curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='Curva ROC')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2, label='Aleatorio')
plt.xlabel('Tasa de Falsos Positivos (FPR)')
plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
plt.title('Curva ROC')
plt.legend()
plt.grid(True)
plt.show()

roc_curve=rendimiento_antes_rrnn.roc()


# Extraer los valores de tasa de verdaderos positivos (TPR) y tasa de falsos positivos (FPR)
fpr = roc_curve[0]
tpr = roc_curve[1]

# Graficar la curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='Curva ROC')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2, label='Aleatorio')
plt.xlabel('Tasa de Falsos Positivos (FPR)')
plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
plt.title('Curva ROC')
plt.legend()
plt.grid(True)
plt.show()

roc_curve=rendimiento_antes_drf.roc()


# Extraer los valores de tasa de verdaderos positivos (TPR) y tasa de falsos positivos (FPR)
fpr = roc_curve[0]
tpr = roc_curve[1]

# Graficar la curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='Curva ROC')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2, label='Aleatorio')
plt.xlabel('Tasa de Falsos Positivos (FPR)')
plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
plt.title('Curva ROC')
plt.legend()
plt.grid(True)
plt.show()

"""Umbral:"""

rendimiento_antes_xgb.find_threshold_by_max_metric('f1')

rendimiento_antes_rrnn.find_threshold_by_max_metric('f1')

"""LIFT:"""

# Obtener el valor de lift del rendimiento anterior
lift = rendimiento_antes_xgb.gains_lift()['lift']

# Crear un rango de valores para el eje x (porcentaje acumulado)
porcentaje_acumulado = [i * 100 / len(lift) for i in range(len(lift))]

# Graficar el gráfico de lift
plt.figure(figsize=(8, 6))
plt.plot(porcentaje_acumulado, lift, color='blue', lw=2, label='LIFT')
plt.xlabel('Porcentaje acumulado de casos')
plt.ylabel('LIFT')
plt.title('Gráfico de LIFT')
plt.legend()
plt.grid(True)
plt.show()

# Obtener el valor de lift del rendimiento anterior
lift = rendimiento_antes_rrnn.gains_lift()['lift']

# Crear un rango de valores para el eje x (porcentaje acumulado)
porcentaje_acumulado = [i * 100 / len(lift) for i in range(len(lift))]

# Graficar el gráfico de lift
plt.figure(figsize=(8, 6))
plt.plot(porcentaje_acumulado, lift, color='blue', lw=2, label='LIFT')
plt.xlabel('Porcentaje acumulado de casos')
plt.ylabel('LIFT')
plt.title('Gráfico de LIFT')
plt.legend()
plt.grid(True)
plt.show()

"""<h1>Nuevo LIFT, según los déciles.</h1>"""

import numpy as np

# Obtener el valor de lift del rendimiento anterior
lift_xgb = rendimiento_antes_xgb.gains_lift()['lift']

# Calcular los deciles
deciles_xgb = np.percentile(lift_xgb, np.arange(0, 101, 10))

# Contar cuántos casos caen en cada intervalo de deciles
count_deciles_xgb = np.histogram(lift_xgb, bins=deciles_xgb)[0]

# Graficar el gráfico de LIFT en deciles
plt.figure(figsize=(8, 6))
plt.bar(range(1, 11), count_deciles_xgb, color='blue', alpha=0.7)
plt.xlabel('Deciles')
plt.ylabel('Número de casos')
plt.title('Número de casos por decil')
plt.xticks(range(1, 11))
plt.grid(axis='y')
plt.show()

# Obtener el valor de lift del rendimiento anterior
lift_rrnn = rendimiento_antes_rrnn.gains_lift()['lift']

# Calcular los deciles
deciles_rrnn = np.percentile(lift_rrnn, np.arange(0, 101, 10))

# Contar cuántos casos caen en cada intervalo de deciles
count_deciles_rrnn = np.histogram(lift_rrnn, bins=deciles)[0]

# Graficar el gráfico de LIFT en deciles
plt.figure(figsize=(8, 6))
plt.bar(range(1, 11), count_deciles_rrnn, color='blue', alpha=0.7)
plt.xlabel('Deciles')
plt.ylabel('Número de casos')
plt.title('Número de casos por decil')
plt.xticks(range(1, 11))
plt.grid(axis='y')
plt.show()

"""SCORER:"""

rendimiento_antes_xgb.F1()

rendimiento_antes_rrnn.F1()

## Otras evaluaciones comunes ##
precision = rendimiento_antes_xgb.precision()
recall = rendimiento_antes_xgb.recall()
accuracy = rendimiento_antes_xgb.accuracy()
especificidad = rendimiento_antes_xgb.specificity()
auc_pr = rendimiento_antes_xgb.aucpr()

print(" 1) Precisión: "+ str(precision))
print(" 2) Recall (Sensibilidad): "+ str(recall))

print(" 3) Exactitud (Accuracy): ", accuracy)
print(" 4) Especificidad: ", especificidad)
print(" 5) AUC-PR:", auc_pr)

## Otras evaluaciones comunes ##
precision = rendimiento_antes_rrnn.precision()
recall = rendimiento_antes_rrnn.recall()
accuracy = rendimiento_antes_rrnn.accuracy()
especificidad = rendimiento_antes_rrnn.specificity()
auc_pr = rendimiento_antes_rrnn.aucpr()

print(" 1) Precisión: "+ str(precision))
print(" 2) Recall (Sensibilidad): "+ str(recall))

print(" 3) Exactitud (Accuracy): ", accuracy)
print(" 4) Especificidad: ", especificidad)
print(" 5) AUC-PR:", auc_pr)