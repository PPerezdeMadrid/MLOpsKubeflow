{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3afc9-14bc-4a4e-b9ce-79543ccf14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problemillas que veo:\n",
    "- como inciar el pipeline\n",
    "- Añadir un input de \"mes\" para modeloScoring.py\n",
    "- Hay que hacer los dockerfile y añadir la imagen al yaml\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "1) Estudiar filtrado de mes (modelo scoring, columna, ...)\n",
    "3) Añadir mes al pipeline??\n",
    "4) Modificar yaml de los archivos cambiados (modeloscoring o preprocesamiento2)\n",
    "5) Estructurar los archivos\n",
    "6) Generar los dockerfile (modificar los de moragon)\n",
    "7) Añadir imagenes de los docker a los yaml y modificar los yaml (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e330d69a-a6ed-4a96-b7b4-b565840d3d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "from typing import NamedTuple\n",
    "from kfp import dsl\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow import feature_column\n",
    "\"\"\"\n",
    "\n",
    "from kfp.dsl import  pipeline, component, Artifact, Dataset, Input, Metrics, Model, Output, InputPath, OutputPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a7ef8f-0542-48f7-a9ea-352822cdaefe",
   "metadata": {},
   "source": [
    "# Descargar archivos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9190ab5e-d32a-4f87-81f0-bce918c5f7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Size    Weight  Sweetness  Softness  HarvestTime  Ripeness  \\\n",
      "0    -1.924968  0.468078   3.077832 -1.472177     0.294799  2.435570   \n",
      "1    -2.409751  0.486870   0.346921 -2.495099    -0.892213  2.067549   \n",
      "2    -0.357607  1.483176   1.568452 -2.645145    -0.647267  3.090643   \n",
      "3    -0.868524  1.566201   1.889605 -1.273761    -1.006278  1.873001   \n",
      "4     0.651825  1.319199  -0.022459 -1.209709    -1.430692  1.078345   \n",
      "...        ...       ...        ...       ...          ...       ...   \n",
      "7995 -6.414403  0.723565   1.134953  2.952763     0.297928 -0.156946   \n",
      "7996  0.851143 -2.217875  -2.812175  0.489249    -1.323410 -2.316883   \n",
      "7997  1.422722 -1.907665  -2.532364  0.964976    -0.562375 -1.834765   \n",
      "7998 -2.131904 -2.742600  -1.008029  2.126946    -0.802632 -3.580266   \n",
      "7999 -2.660879 -2.044666   0.159026  1.499706    -1.581856 -1.605859   \n",
      "\n",
      "       Acidity Quality  \n",
      "0     0.271290    Good  \n",
      "1     0.307325    Good  \n",
      "2     1.427322    Good  \n",
      "3     0.477862    Good  \n",
      "4     2.812442    Good  \n",
      "...        ...     ...  \n",
      "7995  2.398091     Bad  \n",
      "7996  2.113136     Bad  \n",
      "7997  0.697361     Bad  \n",
      "7998  0.423569     Bad  \n",
      "7999  1.435644     Bad  \n",
      "\n",
      "[8000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_original_bananas = pd.read_csv(\"gs://kubeflow-bucket-prueba/banana_quality.csv\")\n",
    "print(df_original_bananas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c36e58b-3539-4254-a9cf-8636937b4fc6",
   "metadata": {},
   "source": [
    "# Creación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023ec711-8af9-44a1-ad66-342590b642c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> datos creados con éxito\n",
      "\n",
      "==> DataFrame guardado en el blob 'datos_05_20240509_0941.csv' en el bucket 'kubeflow-bucket-prueba'.\n"
     ]
    }
   ],
   "source": [
    "# Generar datos\n",
    "# Se lo dejamos a orianna :)\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import generarDatos\n",
    "\n",
    "df_extendido = generarDatos.generar_datos_df(df_original_bananas, 1000000)\n",
    "\n",
    "print(\"\\n==> datos creados con éxito\") \n",
    "\n",
    "def guardar_df_en_gcs(df, bucket_name, blob_name=None):\n",
    "    \"\"\"Guardar un DataFrame de pandas en un archivo CSV en un blob en Google Cloud Storage.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Generar un nombre de blob si no se proporciona uno\n",
    "    if blob_name is None:\n",
    "        now = datetime.now()\n",
    "        mes = now.strftime(\"%m\")\n",
    "        fecha = now.strftime(\"%Y%m%d\")\n",
    "        hora = now.strftime(\"%H%M\")\n",
    "        \n",
    "        blob_name = f\"datos_{mes}_{fecha}_{hora}.csv\"\n",
    "\n",
    "    # Convertir DataFrame a formato CSV\n",
    "    csv_data = df.to_csv(index=False)\n",
    "\n",
    "    # Cargar el archivo CSV en el blob\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.upload_from_string(csv_data, content_type='text/csv')\n",
    "\n",
    "    print(f\"\\n==> DataFrame guardado en el blob '{blob_name}' en el bucket '{bucket_name}'.\")\n",
    "    \n",
    "guardar_df_en_gcs(df_extendido, 'kubeflow-bucket-prueba') # Nombre de mi bucket\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b7b1b-8118-479e-a1ad-9739b8ca507f",
   "metadata": {},
   "source": [
    "# Definición del pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5f1839d-ceb7-4ca9-a548-ef05dbba335a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing type annotation for argument: df",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dsl\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputPath, OutputPath\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocesamiento2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocesamiento2_component\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocesamiento1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocesamiento_component\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodeloscoring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m modeloscoring_component\n",
      "File \u001b[0;32m~/preprocesamiento2.py:12\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m components\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m component\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129;43m@component\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython:3.11\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackages_to_install\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnumpy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mpreprocesamiento2\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Añadimos una columna Nota, Temporada, Estacion\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNotaConsumidor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemporada\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/kfp/dsl/component_decorator.py:119\u001b[0m, in \u001b[0;36mcomponent\u001b[0;34m(func, base_image, target_image, packages_to_install, pip_index_urls, output_component_file, install_kfp_package, kfp_package_path)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    110\u001b[0m         component,\n\u001b[1;32m    111\u001b[0m         base_image\u001b[38;5;241m=\u001b[39mbase_image,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m         install_kfp_package\u001b[38;5;241m=\u001b[39minstall_kfp_package,\n\u001b[1;32m    117\u001b[0m         kfp_package_path\u001b[38;5;241m=\u001b[39mkfp_package_path)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomponent_factory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_component_from_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackages_to_install\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackages_to_install\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpip_index_urls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_index_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_component_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_component_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstall_kfp_package\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstall_kfp_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkfp_package_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfp_package_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/kfp/dsl/component_factory.py:556\u001b[0m, in \u001b[0;36mcreate_component_from_func\u001b[0;34m(func, base_image, target_image, packages_to_install, pip_index_urls, output_component_file, install_kfp_package, kfp_package_path)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    553\u001b[0m     command, args \u001b[38;5;241m=\u001b[39m _get_command_and_args_for_lightweight_component(\n\u001b[1;32m    554\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc)\n\u001b[0;32m--> 556\u001b[0m component_spec \u001b[38;5;241m=\u001b[39m \u001b[43mextract_component_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m component_spec\u001b[38;5;241m.\u001b[39mimplementation \u001b[38;5;241m=\u001b[39m structures\u001b[38;5;241m.\u001b[39mImplementation(\n\u001b[1;32m    558\u001b[0m     container\u001b[38;5;241m=\u001b[39mstructures\u001b[38;5;241m.\u001b[39mContainerSpecImplementation(\n\u001b[1;32m    559\u001b[0m         image\u001b[38;5;241m=\u001b[39mcomponent_image,\n\u001b[1;32m    560\u001b[0m         command\u001b[38;5;241m=\u001b[39mpackages_to_install_command \u001b[38;5;241m+\u001b[39m command,\n\u001b[1;32m    561\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    562\u001b[0m     ))\n\u001b[1;32m    564\u001b[0m module_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(inspect\u001b[38;5;241m.\u001b[39mgetsourcefile(func))\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/kfp/dsl/component_factory.py:422\u001b[0m, in \u001b[0;36mextract_component_interface\u001b[0;34m(func, containerized, description, name)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    421\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[0;32m--> 422\u001b[0m name_to_input_spec, name_to_output_spec \u001b[38;5;241m=\u001b[39m \u001b[43mget_name_to_specs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainerized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m original_docstring \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetdoc(func)\n\u001b[1;32m    425\u001b[0m parsed_docstring \u001b[38;5;241m=\u001b[39m docstring_parser\u001b[38;5;241m.\u001b[39mparse(original_docstring)\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/kfp/dsl/component_factory.py:237\u001b[0m, in \u001b[0;36mget_name_to_specs\u001b[0;34m(signature, containerized)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# no annotation\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annotation \u001b[38;5;241m==\u001b[39m inspect\u001b[38;5;241m.\u001b[39m_empty:\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing type annotation for argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# is Input[Artifact], Input[List[<Artifact>]], <param> (e.g., str), or InputPath(<param>)\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (type_annotations\u001b[38;5;241m.\u001b[39mis_artifact_wrapped_in_Input(annotation) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    241\u001b[0m       \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    242\u001b[0m           annotation,\n\u001b[1;32m    243\u001b[0m           type_annotations\u001b[38;5;241m.\u001b[39mInputPath,\n\u001b[1;32m    244\u001b[0m       ) \u001b[38;5;129;01mor\u001b[39;00m type_utils\u001b[38;5;241m.\u001b[39mis_parameter_type(annotation)):\n",
      "\u001b[0;31mTypeError\u001b[0m: Missing type annotation for argument: df"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2.dsl import InputPath, OutputPath\n",
    "from preprocesamiento2 import preprocesamiento2_component\n",
    "from preprocesamiento1 import preprocesamiento_component\n",
    "from modeloscoring import modeloscoring_component\n",
    "from kfp.gcp import components as gcp_components\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='Preprocesamiento Pipeline',\n",
    "    description='Pipeline para preprocesar datos'\n",
    ")\n",
    "def pipeline_completo(\n",
    "    input_csv: InputPath('CSV'),\n",
    "    output_csv: OutputPath('CSV'),\n",
    "    mes: int\n",
    "):\n",
    "    # Leer el CSV de entrada\n",
    "    read_csv_op = gcp_components.load_file(\n",
    "        input_path=input_csv,\n",
    "        name='Leer CSV de entrada'\n",
    "    )\n",
    "\n",
    "    # Ejecutar el componente de preprocesamiento 1\n",
    "    preprocesamiento_op = preprocesamiento_component(read_csv_op.output)\n",
    "    \n",
    "    # Ejecutar el segundo componente de preprocesamiento\n",
    "    preprocesamiento2_op = preprocesamiento2_component(preprocesamiento_op.output)\n",
    "\n",
    "    # Ejecutar el componente de scoring de modelos\n",
    "    scoring_op = modeloscoring_component(preprocesamiento2_op.output, mes) \n",
    "\n",
    "    # Convertir el DataFrame de predicciones a CSV y guardarlo en GCS\n",
    "    save_csv_op = gcp_components.write_to_gcs(\n",
    "        input_data=scoring_op.output,\n",
    "        output_path=output_csv,\n",
    "        name='Guardar CSV de salida'\n",
    "    )\n",
    "\n",
    "    # Definir dependencias entre operaciones\n",
    "    save_csv_op.after(preprocesamiento_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0fe68-44d3-4b7e-8fd4-59710258028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_input = input(\"Indique el mes (número): \")\n",
    "\n",
    "input_bucket = 'gs://kubeflow-bucket-prueba'\n",
    "input_csv_file = input(\"Inserte el nombre del archivo CSV de los datos extendidos de banana: \")\n",
    "\n",
    "# Crear una instancia del cliente de KFP para interactuar con el Kubeflow Pipelines en GCP\n",
    "client = kfp.Client()\n",
    "\n",
    "# Compilar y ejecutar el pipeline en Kubeflow Pipelines en GCP\n",
    "client.create_run_from_pipeline_func(\n",
    "    pipeline_completo,\n",
    "    arguments={\n",
    "        'input_csv': input_bucket + '/' + input_csv_file,\n",
    "        'output_csv': 'gs://kubeflow-bucket-prueba/scoring_{mes}.csv',\n",
    "        'mes'= mes_input\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
